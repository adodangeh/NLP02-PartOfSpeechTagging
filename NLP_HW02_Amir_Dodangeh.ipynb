{"cells":[{"cell_type":"code","execution_count":65,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1367,"status":"ok","timestamp":1622189286778,"user":{"displayName":"Amir Dodangeh","photoUrl":"","userId":"03691380656141451894"},"user_tz":-270},"id":"oKwChQ2oehO2","outputId":"90a8e08c-9beb-4769-fcb1-02ade9ef6740"},"outputs":[{"name":"stderr","output_type":"stream","text":["IOPub data rate exceeded.\n","The notebook server will temporarily stop sending output\n","to the client in order to avoid crashing it.\n","To change this limit, set the config variable\n","`--NotebookApp.iopub_data_rate_limit`.\n","\n","Current values:\n","NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n","NotebookApp.rate_limit_window=3.0 (secs)\n","\n"]}],"source":["import sys\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","\n","# Opening and reading the `Input.txt` file\n","train = open(\"/content/gdrive/My Drive/Colab Notebooks/NLP/HW02/Train.txt\").read()\n","\n","test = open(\"/content/gdrive/My Drive/Colab Notebooks/NLP/HW02/Test.txt\").read()\n","\n","\n","train2=str(train)\n","print(train2)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"output_embedded_package_id":"1OxopaOsxcEz2kM_WyXTYxjvS3XrXtCxv"},"id":"DvIOiIsH85L4","outputId":"1a2a906c-b70a-4b81-8be7-093cdfeaf147"},"outputs":[],"source":["file = open(\"/content/gdrive/My Drive/Colab Notebooks/NLP/HW02/Test.txt\")\n","\n","line = file.read().replace(\"\\n\", \" \")\n","file.close()\n","\n","print(line)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1622188150452,"user":{"displayName":"Amir Dodangeh","photoUrl":"","userId":"03691380656141451894"},"user_tz":-270},"id":"o845LmrrbMxU"},"outputs":[{"name":"stdout","output_type":"stream","text":["['م', 'ي', 'ش', 'و', 'ن', 'د', ' ', 'V', '\\n', '.', ' ', 'D', 'E', 'L', 'M', '\\n', '\\n', 'ن', 'ت', 'ي', 'ج', 'ه', 'ي', ' ', 'N', '\\n', 'ب', 'ح', 'ث', ' ', 'N', '\\n', 'ب', 'ا', 'ل', 'ا', ' ', 'A', 'D', 'J', '\\n', 'ا', 'ي', 'ن', ' ', 'P', 'R', 'O', '\\n', 'ا', 'س', 'ت', ' ', 'V', '\\n', 'ك', 'ه', ' ', 'C', 'O', 'N', '\\n', 'ف', 'ع', 'ل', 'ه', 'ا', ' ', 'N', '\\n', 'ا', 'ز', ' ', 'P', '\\n', 'ن', 'ظ', 'ر', ' ', 'N', '\\n', 'س', 'ا', 'خ', 'ت', 'م', 'ا', 'ن', ' ', 'N', '\\n', 'ب', 'ه', ' ', 'P', '\\n', 'س', 'ه', ' ', 'N', '\\n', 'گ', 'ر', 'و', 'ه', ' ', 'N', '\\n', 'س', 'ا', 'د', 'ه', ' ', 'A', 'D', 'J', '\\n', '،', ' ', 'D', 'E', 'L', 'M', '\\n', 'پ', 'ي', 'ش', 'و', 'ن', 'د', 'ي', ' ', 'A', 'D', 'J', '\\n', 'و', ' ', 'C', 'O', 'N', '\\n', 'گ', 'ر', 'و', 'ه', 'ي', ' ', 'A', 'D', 'J', '\\n', 'ت', 'ق', 'س', 'ي', 'م', ' ', 'N', '\\n', 'م', 'ي', 'ش', 'و', 'ن', 'د', ' ', 'V', '\\n', '.', ' ', 'D', 'E', 'L', 'M', '\\n', '\\n', 'ص', 'و', 'ر', 'ت', 'ه', 'ا', 'ي', ' ', 'N', '\\n', 'گ', 'س', 'ت', 'ر', 'ش', 'ي', 'ا', 'ف', 'ت', 'ه', ' ', 'A', 'D']\n"]}],"source":["# Importing libraries\n","import nltk\n","import numpy as np\n","import pandas as pd\n","import random\n","from sklearn.model_selection import train_test_split\n","import pprint, time\n"," \n","#download the treebank corpus from nltk\n","#nltk.download('treebank')\n"," \n","#download the universal tagset from nltk\n","#nltk.download('universal_tagset')\n"," \n","# reading the Treebank tagged sentences\n","nltk_data = list(train_tagged_words)\n"," \n","#print the first two sentences along with tags\n","print(nltk_data[:200])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"3TIpA2-ffYjJ"},"outputs":[],"source":["# split data into training and validation set in the ratio 80:20\n","train_set,test_set =train_test_split(train_tagged_words,train_size=0.80,test_size=0.20,random_state = 101)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1622188150838,"user":{"displayName":"Amir Dodangeh","photoUrl":"","userId":"03691380656141451894"},"user_tz":-270},"id":"1-lzpx05glbO"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'ميشوند V\\n. DELM\\n\\nنتيجهي N\\nبحث N\\nبالا ADJ\\nاين PRO\\nا'"]},"execution_count":null,"metadata":{},"output_type":"execute_result"}],"source":["# check some of the tagged words.\n","train_tagged_words[:50]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":430,"status":"ok","timestamp":1622188151256,"user":{"displayName":"Amir Dodangeh","photoUrl":"","userId":"03691380656141451894"},"user_tz":-270},"id":"KMZtI6RvjZ4L"},"outputs":[{"name":"stdout","output_type":"stream","text":["م\n","ي\n","ش\n","و\n","ن\n","د\n"," \n","V\n","\n","\n",".\n"," \n","D\n","E\n","L\n","M\n","\n","\n","\n","\n","ن\n","ت\n","ي\n"]}],"source":["#print each word with its respective tag for first two sentences\n","for sent in train_tagged_words[:20]:\n","  for tuple in sent:\n","    print(tuple)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":363},"executionInfo":{"elapsed":18,"status":"error","timestamp":1622188151260,"user":{"displayName":"Amir Dodangeh","photoUrl":"","userId":"03691380656141451894"},"user_tz":-270},"id":"8RXiUgwWfOAZ"},"outputs":[{"ename":"ValueError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m\u003cipython-input-72-ac5ce86019b0\u003e\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#use set datatype to check how many unique tags are present in training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----\u003e 2\u001b[0;31m \u001b[0mtags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mtag\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtag\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_tagged_words\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m\u003cipython-input-72-ac5ce86019b0\u003e\u001b[0m in \u001b[0;36m\u003csetcomp\u003e\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#use set datatype to check how many unique tags are present in training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----\u003e 2\u001b[0;31m \u001b[0mtags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mtag\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtag\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_tagged_words\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"]}],"source":["#use set datatype to check how many unique tags are present in training data\n","tags = {tag for word,tag in train_tagged_words}\n","print(len(tags))\n","print(tags)\n"," \n","# check total words in vocabulary\n","vocab = {word for word,tag in train_tagged_words}\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"ecuVhCDzfkVE"},"outputs":[],"source":["# create list of train and test tagged words\n","train_tagged_words = [ tup for sent in train_set for tup in sent ]\n","test_tagged_words = [ tup for sent in test_set for tup in sent ]\n","print(len(train_tagged_words))\n","print(len(test_tagged_words))"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyOAKKoHjAzcpOmWy1rEN8/c","name":"NLP_HW02_Amir_Dodangeh.ipynb","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}